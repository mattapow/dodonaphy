
@article{billera2001geometry,
	title = {Geometry of the {Space} of {Phylogenetic} {Trees}},
	volume = {27},
	issn = {01968858},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0196885801907596},
	doi = {10.1006/aama.2001.0759},
	language = {en},
	number = {4},
	urldate = {2020-11-13},
	journal = {Advances in Applied Mathematics},
	author = {Billera, Louis J. and Holmes, Susan P. and Vogtmann, Karen},
	month = nov,
	year = {2001},
	pages = {733--767},
	file = {billera_2001_geometry of the space of phylogenetic trees.pdf:/Users/151569/OneDrive - UTS/ZotFile/Advances in Applied Mathematics/2001/billera_2001_geometry of the space of phylogenetic trees.pdf:application/pdf},
}

@article{katherine2016review,
	title = {Review {Paper}: {The} {Shape} of {Phylogenetic} {Treespace}},
	issn = {1063-5157, 1076-836X},
	shorttitle = {Review {Paper}},
	url = {https://academic.oup.com/sysbio/article-lookup/doi/10.1093/sysbio/syw025},
	doi = {10.1093/sysbio/syw025},
	language = {en},
	urldate = {2020-11-13},
	journal = {Systematic Biology},
	author = {Katherine, St. John},
	month = jun,
	year = {2016},
	pages = {syw025},
	file = {katherine_2016_review paper.pdf:/Users/151569/OneDrive - UTS/ZotFile/Systematic Biology/2016/katherine_2016_review paper.pdf:application/pdf},
}

@techreport{matsumoto2020novel,
	type = {preprint},
	title = {Novel metric for hyperbolic phylogenetic tree embeddings},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.10.09.334243},
	abstract = {Advances in experimental technologies such as DNA sequencing have opened up new avenues for the applications of phylogenetic methods to various fields beyond their traditional application in evolutionary investigations, extending to the fields of development, differentiation, cancer genomics, and immunogenomics. Thus, the importance of phylogenetic methods is increasingly being recognized, and the development of a novel phylogenetic approach can contribute to several areas of research. Recently, the use of hyperbolic geometry has attracted attention in artificial intelligence research. Hyperbolic space can better represent a hierarchical structure compared to Euclidean space, and can therefore be useful for describing and analyzing a phylogenetic tree. In this study, we developed a novel metric that considers the characteristics of a phylogenetic tree for representation in hyperbolic space. We compared the performance of the proposed hyperbolic embeddings, general hyperbolic embeddings, and Euclidean embeddings, and confirmed that our method could be used to more precisely reconstruct evolutionary distance. We also demonstrate that our approach is useful for predicting the nearest-neighbor node in a partial phylogenetic tree with missing nodes. This study highlights the utility of adopting a geometric approach for further advancing the applications of phylogenetic methods.
          
            The demo code is attached as a supplementary file in a compiled jupyter notebook. The code used for analyses is available on GitHub at
            https://github.com/hmatsu1226/HyPhyTree
            .},
	language = {en},
	urldate = {2020-11-13},
	institution = {Bioinformatics},
	author = {Matsumoto, Hirotaka and Mimori, Takahiro and Fukunaga, Tsukasa},
	month = oct,
	year = {2020},
	doi = {10.1101/2020.10.09.334243},
	file = {matsumoto_2020_novel metric for hyperbolic phylogenetic tree embeddings.pdf:/Users/151569/OneDrive - UTS/ZotFile/Bioinformatics/2020/matsumoto_2020_novel metric for hyperbolic phylogenetic tree embeddings.pdf:application/pdf},
}

@inproceedings{dinh2017probabilistic,
	address = {International Convention Centre, Sydney, Australia},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Probabilistic {Path} {Hamiltonian} {Monte} {Carlo}},
	volume = {70},
	abstract = {Hamiltonian Monte Carlo (HMC) is an efﬁcient and effective means of sampling posterior distributions on Euclidean space, which has been extended to manifolds with boundary. However, some applications require an extension to more general spaces. For example, phylogenetic (evolutionary) trees are deﬁned in terms of both a discrete graph and associated continuous parameters; although one can represent these aspects using a single connected space, this rather complex space is not suitable for existing HMC algorithms. In this paper, we develop Probabilistic Path HMC (PPHMC) as a ﬁrst step to sampling distributions on spaces with intricate combinatorial structure. We deﬁne PPHMC on orthant complexes, show that the resulting Markov chain is ergodic, and provide a promising implementation for the case of phylogenetic trees in opensource software. We also show that a surrogate function to ease the transition across a boundary on which the log-posterior has discontinuous derivatives can greatly improve efﬁciency.},
	language = {en},
	publisher = {PMLR},
	author = {Dinh, Vu and Bilge, Arman and Zhang, Cheng and Matsen, Frederick A},
	year = {2017},
	pages = {10},
	file = {dinh_2017_probabilistic path hamiltonian monte carlo.pdf:/Users/151569/OneDrive - UTS/ZotFile/PMLR/2017/dinh_2017_probabilistic path hamiltonian monte carlo.pdf:application/pdf},
}

@article{whidden2015quantifying,
	title = {Quantifying {MCMC} {Exploration} of {Phylogenetic} {Tree} {Space}},
	volume = {64},
	issn = {1076-836X, 1063-5157},
	url = {https://academic.oup.com/sysbio/article/64/3/472/1632660},
	doi = {10.1093/sysbio/syv006},
	language = {en},
	number = {3},
	urldate = {2020-11-16},
	journal = {Systematic Biology},
	author = {Whidden, Chris and Matsen, Frederick A.},
	month = may,
	year = {2015},
	note = {tex.ids: whidden2015quantifyinga
publisher: Oxford Academic},
	pages = {472--491},
	file = {whidden_2015_quantifying mcmc exploration of phylogenetic tree space.pdf:/Users/151569/OneDrive - UTS/ZotFile/Systematic Biology/2015/whidden_2015_quantifying mcmc exploration of phylogenetic tree space.pdf:application/pdf;Snapshot:/Users/151569/.Zotero/storage/P2UB7HSY/1632660.html:text/html},
}

@article{sumner2017dimensional,
	title = {Dimensional {Reduction} for the {General} {Markov} {Model} on {Phylogenetic} {Trees}},
	volume = {79},
	copyright = {Bulletin of Mathematical Biology is a copyright of Springer, 2017.},
	issn = {00928240},
	url = {https://search.proquest.com/docview/1872750622/abstract/A39BF4D1E7D4F6BPQ/1},
	doi = {http://dx.doi.org/10.1007/s11538-017-0249-6},
	abstract = {We present a method of dimensional reduction for the general Markov model of sequence evolution on a phylogenetic tree. We show that taking certain linear combinations of the associated random variables (site pattern counts) reduces the dimensionality of the model from exponential in the number of extant taxa, to quadratic in the number of taxa, while retaining the ability to statistically identify phylogenetic divergence events. A key feature is the identification of an invariant subspace which depends only bilinearly on the model parameters, in contrast to the usual multi-linear dependence in the full space. We discuss potential applications including the computation of split (edge) weights on phylogenetic trees from observed sequence data.},
	language = {English},
	number = {3},
	urldate = {2020-12-03},
	journal = {Bulletin of Mathematical Biology; New York},
	author = {Sumner, Jeremy G.},
	month = mar,
	year = {2017},
	note = {Num Pages: 619-634
Place: New York, Netherlands, New York
Publisher: Springer Nature B.V.},
	keywords = {Affine group, Markov chains, Representation theory},
	pages = {619--634},
	file = {sumner_2017_dimensional reduction for the general markov model on phylogenetic trees.pdf:/Users/151569/OneDrive - UTS/ZotFile/Bulletin of Mathematical Biology\; New York/2017/sumner_2017_dimensional reduction for the general markov model on phylogenetic trees.pdf:application/pdf},
}

@inproceedings{monath2019gradientbased,
	address = {Anchorage AK USA},
	title = {Gradient-based {Hierarchical} {Clustering} using {Continuous} {Representations} of {Trees} in {Hyperbolic} {Space}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330997},
	doi = {10.1145/3292500.3330997},
	abstract = {Hierarchical clustering is typically performed using algorithmicbased optimization searching over the discrete space of trees. While these optimization methods are often effective, their discreteness restricts them from many of the benefits of their continuous counterparts, such as scalable stochastic optimization and the joint optimization of multiple objectives or components of a model (e.g. end-to-end training). In this paper, we present an approach for hierarchical clustering that searches over continuous representations of trees in hyperbolic space by running gradient descent. We compactly represent uncertainty over tree structures with vectors in the Poincaré ball. We show how the vectors can be optimized using an objective related to recently proposed cost functions for hierarchical clustering [16, 49]. Using our method with a mini-batch stochastic gradient descent inference procedure, we are able to outperform prior work on clustering millions of ImageNet images by 15 points of dendrogram purity. Further, our continuous tree representation can be jointly optimized in multi-task learning applications offering a 9 point improvement over baseline methods.},
	language = {en},
	urldate = {2020-12-09},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Monath, Nicholas and Zaheer, Manzil and Silva, Daniel and McCallum, Andrew and Ahmed, Amr},
	month = jul,
	year = {2019},
	pages = {714--722},
	file = {monath_2019_gradient-based hierarchical clustering using continuous representations of.pdf:/Users/151569/OneDrive - UTS/ZotFile/ACM/2019/monath_2019_gradient-based hierarchical clustering using continuous representations of.pdf:application/pdf},
}

@article{nye2011principal,
	title = {Principal components analysis in the space of phylogenetic trees},
	volume = {39},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1324563353},
	doi = {10.1214/11-AOS915},
	abstract = {Phylogenetic analysis of DNA or other data commonly gives rise to a collection or sample of inferred evolutionary trees. Principal Components Analysis (PCA) cannot be applied directly to collections of trees since the space of evolutionary trees on a fixed set of taxa is not a vector space. This paper describes a novel geometrical approach to PCA in tree-space that constructs the first principal path in an analogous way to standard linear Euclidean PCA. Given a data set of phylogenetic trees, a geodesic principal path is sought that maximizes the variance of the data under a form of projection onto the path. Due to the high dimensionality of tree-space and the nonlinear nature of this problem, the computational complexity is potentially very high, so approximate optimization algorithms are used to search for the optimal path. Principal paths identified in this way reveal and quantify the main sources of variation in the original collection of trees in terms of both topology and branch lengths. The approach is illustrated by application to simulated sets of trees and to a set of gene trees from metazoan (animal) species.},
	language = {EN},
	number = {5},
	urldate = {2020-12-21},
	journal = {Annals of Statistics},
	author = {Nye, Tom M. W.},
	month = oct,
	year = {2011},
	mrnumber = {MR2906884},
	zmnumber = {1231.62110},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Phylogeny, geodesic, principal component},
	pages = {2716--2739},
	file = {nye_2011_principal components analysis in the space of phylogenetic trees.pdf:/Users/151569/OneDrive - UTS/ZotFile/Annals of Statistics/2011/nye_2011_principal components analysis in the space of phylogenetic trees.pdf:application/pdf;Snapshot:/Users/151569/.Zotero/storage/AE35BP87/1324563353.html:text/html},
}

@inproceedings{sala2018representation,
	title = {Representation {Tradeoffs} for {Hyperbolic} {Embeddings}},
	url = {http://proceedings.mlr.press/v80/sala18a.html},
	abstract = {Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures. We give a combinatorial construction that embeds trees into hyperbolic space with arbi...},
	language = {en},
	urldate = {2020-12-22},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Sala, Frederic and Sa, Chris De and Gu, Albert and Re, Christopher},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {4460--4469},
	file = {Snapshot:/Users/151569/.Zotero/storage/T9STWJYF/sala18a.html:text/html;Snapshot:/Users/151569/.Zotero/storage/M6QA45M5/sala18a.html:text/html;sala_2018_representation tradeoffs for hyperbolic embeddings.pdf:/Users/151569/OneDrive - UTS/ZotFile/PMLR/2018/sala_2018_representation tradeoffs for hyperbolic embeddings.pdf:application/pdf},
}

@inproceedings{nagano2019wrapped,
	title = {A {Wrapped} {Normal} {Distribution} on {Hyperbolic} {Space} for {Gradient}-{Based} {Learning}},
	url = {http://proceedings.mlr.press/v97/nagano19a.html},
	abstract = {Hyperbolic space is a geometry that is known to be well-suited for representation learning of data with an underlying hierarchical structure. In this paper, we present a novel hyperbolic distributi...},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Nagano, Yoshihiro and Yamaguchi, Shoichiro and Fujita, Yasuhiro and Koyama, Masanori},
	month = may,
	year = {2019},
	note = {tex.ids= nagano2019wrappeda
ISSN: 2640-3498},
	pages = {4693--4702},
	file = {nagano_2019_a wrapped normal distribution on hyperbolic space for gradient-based learning.pdf:/Users/151569/OneDrive - UTS/ZotFile/PMLR/2019/nagano_2019_a wrapped normal distribution on hyperbolic space for gradient-based learning.pdf:application/pdf;Snapshot:/Users/151569/.Zotero/storage/NHL789IP/nagano19a.html:text/html},
}

@article{keller-ressel2019hydra,
	title = {Hydra: {A} method for strain-minimizing hyperbolic embedding of network- and distance-based data},
	shorttitle = {Hydra},
	url = {http://arxiv.org/abs/1903.08977},
	abstract = {We introduce hydra (hyperbolic distance recovery and approximation), a new method for embedding network- or distance-based data into hyperbolic space. We show mathematically that hydra satisfies a certain optimality guarantee: It minimizes the `hyperbolic strain' between original and embedded data points. Moreover, it recovers points exactly, when they are located on a hyperbolic submanifold of the feature space. Testing on real network data we show that the embedding quality of hydra is competitive with existing hyperbolic embedding methods, but achieved at substantially shorter computation time. An extended method, termed hydra+, outperforms existing methods in both computation time and embedding quality.},
	urldate = {2021-01-07},
	journal = {arXiv:1903.08977 [cs, math, stat]},
	author = {Keller-Ressel, Martin and Nargang, Stephanie},
	month = sep,
	year = {2019},
	note = {arXiv: 1903.08977},
	keywords = {Statistics - Computation, Computer Science - Machine Learning, 68Wxx, 51M10, G.2.2, G.3, Mathematics - Metric Geometry},
	file = {arXiv.org Snapshot:/Users/151569/.Zotero/storage/L9MXDC2T/1903.html:text/html;keller-ressel_2019_hydra.pdf:/Users/151569/OneDrive - UTS/ZotFile/arXiv1903.08977 [cs, math, stat]/2019/keller-ressel_2019_hydra.pdf:application/pdf},
}

@article{chami2020trees,
	title = {From {Trees} to {Continuous} {Embeddings} and {Back}: {Hyperbolic} {Hierarchical} {Clustering}},
	shorttitle = {From {Trees} to {Continuous} {Embeddings} and {Back}},
	url = {https://arxiv.org/abs/2010.00402v1},
	abstract = {Similarity-based Hierarchical Clustering (HC) is a classical unsupervised
machine learning algorithm that has traditionally been solved with heuristic
algorithms like Average-Linkage. Recently, Dasgupta reframed HC as a discrete
optimization problem by introducing a global cost function measuring the
quality of a given tree. In this work, we provide the first continuous
relaxation of Dasgupta's discrete optimization problem with provable quality
guarantees. The key idea of our method, HypHC, is showing a direct
correspondence from discrete trees to continuous representations (via the
hyperbolic embeddings of their leaf nodes) and back (via a decoding algorithm
that maps leaf embeddings to a dendrogram), allowing us to search the space of
discrete binary trees with continuous optimization. Building on analogies
between trees and hyperbolic space, we derive a continuous analogue for the
notion of lowest common ancestor, which leads to a continuous relaxation of
Dasgupta's discrete objective. We can show that after decoding, the global
minimizer of our continuous relaxation yields a discrete tree with a (1 +
epsilon)-factor approximation for Dasgupta's optimal tree, where epsilon can be
made arbitrarily small and controls optimization challenges. We experimentally
evaluate HypHC on a variety of HC benchmarks and find that even approximate
solutions found with gradient descent have superior clustering quality than
agglomerative heuristics or other gradient based algorithms. Finally, we
highlight the flexibility of HypHC using end-to-end training in a downstream
classification task.},
	language = {en},
	urldate = {2021-01-21},
	author = {Chami, Ines and Gu, Albert and Chatziafratis, Vaggos and Ré, Christopher},
	month = oct,
	year = {2020},
	file = {Snapshot:/Users/151569/.Zotero/storage/EBX34EUH/2010.html:text/html;chami_2020_from trees to continuous embeddings and back.pdf:/Users/151569/OneDrive - UTS/ZotFile/undefined/2020/chami_2020_from trees to continuous embeddings and back.pdf:application/pdf;chami_2020_from trees to continuous embeddings and back.pdf:/Users/151569/OneDrive - UTS/ZotFile/undefined/2020/chami_2020_from trees to continuous embeddings and back2.pdf:application/pdf},
}

@article{greenberg2020data,
	title = {Data {Structures} \& {Algorithms} for {Exact} {Inference} in {Hierarchical} {Clustering}},
	url = {http://arxiv.org/abs/2002.11661},
	abstract = {Hierarchical clustering is a fundamental task often used to discover meaningful structures in data, such as phylogenetic trees, taxonomies of concepts, subtypes of cancer, and cascades of particle decays in particle physics. Typically approximate algorithms are used for inference due to the combinatorial number of possible hierarchical clusterings. In contrast to existing methods, we present novel dynamic-programming algorithms for exact inference in hierarchical clustering based on a novel trellis data structure, and we prove that we can exactly compute the partition function, maximum likelihood hierarchy, and marginal probabilities of sub-hierarchies and clusters. Our algorithms scale in time and space proportional to the powerset of N elements which is superexponentially more eﬃcient than explicitly considering each of the (2N − 3)!! possible hierarchies. Also, for larger datasets where our exact algorithms become infeasible, we introduce an approximate algorithm based on a sparse trellis that compares well to other benchmarks. Exact methods are relevant to data analyses in particle physics and for ﬁnding correlations among gene expression in cancer genomics, and we give examples in both areas, where our algorithms outperform greedy and beam search baselines. In addition, we consider Dasgupta’s cost [1] with synthetic data.},
	language = {en},
	urldate = {2021-02-10},
	journal = {arXiv:2002.11661 [physics, stat]},
	author = {Greenberg, Craig S. and Macaluso, Sebastian and Monath, Nicholas and Lee, Ji-Ah and Flaherty, Patrick and Cranmer, Kyle and McGregor, Andrew and McCallum, Andrew},
	month = oct,
	year = {2020},
	note = {tex.ids= greenberg2020dataa
arXiv: 2002.11661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Data Structures and Algorithms, Physics - Data Analysis, Statistics and Probability},
	file = {greenberg_2020_data structures & algorithms for exact inference in hierarchical clustering.pdf:/Users/151569/OneDrive - UTS/ZotFile/arXiv2002.11661 [physics, stat]/2020/greenberg_2020_data structures & algorithms for exact inference in hierarchical clustering.pdf:application/pdf},
}

@inproceedings{dasgupta2016cost,
	address = {New York, NY, USA},
	series = {{STOC} '16},
	title = {A cost function for similarity-based hierarchical clustering},
	isbn = {978-1-4503-4132-5},
	url = {https://doi.org/10.1145/2897518.2897527},
	doi = {10.1145/2897518.2897527},
	abstract = {The development of algorithms for hierarchical clustering has been hampered by a shortage of precise objective functions. To help address this situation, we introduce a simple cost function on hierarchies over a set of points, given pairwise similarities between those points. We show that this criterion behaves sensibly in canonical instances and that it admits a top-down construction procedure with a provably good approximation ratio.},
	urldate = {2021-02-11},
	booktitle = {Proceedings of the forty-eighth annual {ACM} symposium on {Theory} of {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Dasgupta, Sanjoy},
	month = jun,
	year = {2016},
	keywords = {approximation algorithm, Hierarchical clustering},
	pages = {118--127},
	file = {dasgupta_2016_a cost function for similarity-based hierarchical clustering.pdf:/Users/151569/OneDrive - UTS/ZotFile/Association for Computing Machinery/2016/dasgupta_2016_a cost function for similarity-based hierarchical clustering.pdf:application/pdf},
}

@article{iuchi2021representation,
	title = {Representation learning applications in biological sequence analysis},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.02.26.433129v1},
	doi = {10.1101/2021.02.26.433129},
	abstract = {{\textless}p{\textgreater}Remarkable advances in high-throughput sequencing have resulted in rapid data accumulation, and analyzing biological (DNA/RNA/protein) sequences to discover new insights in biology has become more critical and challenging. To tackle this issue, the application of natural language processing (NLP) to biological sequence analysis has received increased attention, because biological sequences are regarded as sentences and k-mers in these sequences as words. Embedding is an essential step in NLP, which converts words into vectors. This transformation is called representation learning and can be applied to biological sequences. Vectorized biological sequences can be used for function and structure estimation, or as inputs for other probabilistic models. Given the importance and growing trend in the application of representation learning in biology, here, we review the existing knowledge in representation learning for biological sequence analysis.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-03},
	journal = {bioRxiv},
	author = {Iuchi, Hitoshi and Matsutani, Taro and Yamada, Keisuke and Iwano, Natsuki and Sumi, Shunsuke and Hosoda, Shion and Zhao, Shitao and Fukunaga, Tsukasa and Hamada, Michiaki},
	month = feb,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.02.26.433129},
	file = {iuchi_2021_representation learning applications in biological sequence analysis.pdf:/Users/151569/OneDrive - UTS/ZotFile/bioRxiv/2021/iuchi_2021_representation learning applications in biological sequence analysis.pdf:application/pdf},
}

@inproceedings{gu2018learning,
	title = {Learning {Mixed}-{Curvature} {Representations} in {Product} {Spaces}},
	url = {https://openreview.net/forum?id=HJxeWnCcF7},
	abstract = {Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.},
	language = {en},
	urldate = {2021-03-04},
	author = {Gu, Albert and Sala, Frederic and Gunel, Beliz and Ré, Christopher},
	month = sep,
	year = {2018},
	file = {Full Text PDF:/Users/151569/.Zotero/storage/N9ZK3L82/Gu et al. - 2018 - Learning Mixed-Curvature Representations in Produc.pdf:application/pdf;Snapshot:/Users/151569/.Zotero/storage/RFZGZTXK/forum.html:text/html},
}

@article{bose2020latent,
	title = {Latent {Variable} {Modelling} with {Hyperbolic} {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2002.06336},
	abstract = {The choice of approximate posterior distributions plays a central role in stochastic variational inference (SVI). One effective solution is the use of normalizing flows {\textbackslash}cut\{defined on Euclidean spaces\} to construct flexible posterior distributions. However, one key limitation of existing normalizing flows is that they are restricted to the Euclidean space and are ill-equipped to model data with an underlying hierarchical structure. To address this fundamental limitation, we present the first extension of normalizing flows to hyperbolic spaces. We first elevate normalizing flows to hyperbolic spaces using coupling transforms defined on the tangent bundle, termed Tangent Coupling (\${\textbackslash}mathcal\{TC\}\$). We further introduce Wrapped Hyperboloid Coupling (\${\textbackslash}mathcal\{W\}{\textbackslash}mathbb\{H\}C\$), a fully invertible and learnable transformation that explicitly utilizes the geometric structure of hyperbolic spaces, allowing for expressive posteriors while being efficient to sample from. We demonstrate the efficacy of our novel normalizing flow over hyperbolic VAEs and Euclidean normalizing flows. Our approach achieves improved performance on density estimation, as well as reconstruction of real-world graph data, which exhibit a hierarchical structure. Finally, we show that our approach can be used to power a generative model over hierarchical data using hyperbolic latent variables.},
	urldate = {2021-04-16},
	journal = {arXiv:2002.06336 [cs, stat]},
	author = {Bose, Avishek Joey and Smofsky, Ariella and Liao, Renjie and Panangaden, Prakash and Hamilton, William L.},
	month = aug,
	year = {2020},
	note = {arXiv: 2002.06336},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/151569/.Zotero/storage/JVZXDCY4/Bose et al. - 2020 - Latent Variable Modelling with Hyperbolic Normaliz.pdf:application/pdf;arXiv.org Snapshot:/Users/151569/.Zotero/storage/VIXVVQVM/2002.html:text/html},
}

@article{wilson2021learning,
	title = {Learning phylogenetic trees as hyperbolic point configurations},
	url = {http://arxiv.org/abs/2104.11430},
	abstract = {An alternative to independent pairwise distance estimation is proposed that uses hyperbolic geometry to jointly estimate pairwise distances subject to a weakening of the four point condition that characterises tree metrics. Specifically, taxa are represented as points in hyperbolic space such that the distance between a pair of points accounts for the site differences between the corresponding taxa. The proposed algorithm iteratively rearranges the points to increase an objective function that is shown empirically to increase the log-likelihood employed in tree search. Unlike the log-likelihood on tree space, the proposed objective function is differentiable, allowing for the use of gradient-based techniques in its optimisation. It is shown that the error term in the weakened four point condition is bounded by a linear function of the radius parameter of the hyperboloid model, which controls the curvature of the space. The error may thus be made as small as desired, within the bounds of computational precision.},
	urldate = {2021-05-23},
	journal = {arXiv:2104.11430 [cs]},
	author = {Wilson, Benjamin},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.11430},
	keywords = {Computer Science - Machine Learning, 92B20 (Primary) 92B10, 68T05 (Secondary), I.2.0},
	file = {arXiv Fulltext PDF:/Users/151569/.Zotero/storage/XZXXRS53/Wilson - 2021 - Learning phylogenetic trees as hyperbolic point co.pdf:application/pdf;arXiv.org Snapshot:/Users/151569/.Zotero/storage/8A3CWKSM/2104.html:text/html},
}

@article{layer2017phylogenetic,
	title = {Phylogenetic trees and {Euclidean} embeddings},
	volume = {74},
	issn = {0303-6812, 1432-1416},
	url = {http://link.springer.com/10.1007/s00285-016-1018-0},
	doi = {10.1007/s00285-016-1018-0},
	abstract = {It was recently observed by de Vienne et al. (Syst Biol 60(6):826–832, 2011) that a simple square root transformation of distances between taxa on a phylogenetic tree allowed for an embedding of the taxa into Euclidean space. While the justiﬁcation for this was based on a diffusion model of continuous character evolution along the tree, here we give a direct and elementary explanation for it that provides substantial additional insight. We use this embedding to reinterpret the differences between the NJ and BIONJ tree building algorithms, providing one illustration of how this embedding reﬂects tree structures in data.},
	language = {en},
	number = {1-2},
	urldate = {2021-07-19},
	journal = {Journal of Mathematical Biology},
	author = {Layer, Mark and Rhodes, John A.},
	month = jan,
	year = {2017},
	note = {tex.ids= layer2017phylogenetica},
	pages = {99--111},
	file = {s00285-016-1018-0.pdf:/Users/151569/.Zotero/storage/TDHZXFR3/s00285-016-1018-0.pdf:application/pdf},
}

@article{devienne2011euclidean,
	title = {Euclidean {Nature} of {Phylogenetic} {Distance} {Matrices}},
	volume = {60},
	issn = {1063-5157},
	url = {https://doi.org/10.1093/sysbio/syr066},
	doi = {10.1093/sysbio/syr066},
	abstract = {Phylogenies are fundamental to comparative biology as they help to identify independent events on which statistical tests rely. Two groups of phylogenetic comparative methods (PCMs) can be distinguished: those that take phylogenies into account by introducing explicit models of evolution and those that only consider phylogenies as a statistical constraint and aim at partitioning trait values into a phylogenetic component (phylogenetic inertia) and one or multiple specific components related to adaptive evolution. The way phylogenetic information is incorporated into the PCMs depends on the method used. For the first group of methods, phylogenies are converted into variance–covariance matrices of traits following a given model of evolution such as Brownian motion (BM). For the second group of methods, phylogenies are converted into distance matrices that are subsequently transformed into Euclidean distances to perform principal coordinate analyses. Here, we show that simply taking the elementwise square root of a distance matrix extracted from a phylogenetic tree ensures having a Euclidean distance matrix. This is true for any type of distances between species (patristic or nodal) and also for trees harboring multifurcating nodes. Moreover, we illustrate that this simple transformation using the square root imposes less geometric distortion than more complex transformations classically used in the literature such as the Cailliez method. Given the Euclidean nature of the elementwise square root of phylogenetic distance matrices, the positive semidefinitiveness of the phylogenetic variance–covariance matrix of a trait following a BM model, or related models of trait evolution, can be established. In that way, we build a bridge between the two groups of statistical methods widely used in comparative analysis. These results should be of great interest for ecologists and evolutionary biologists performing statistical analyses incorporating phylogenies.},
	number = {6},
	urldate = {2021-07-19},
	journal = {Systematic Biology},
	author = {de Vienne, Damien M. and Aguileta, Gabriela and Ollier, Sébastien},
	month = dec,
	year = {2011},
	pages = {826--832},
	file = {Full Text PDF:/Users/151569/.Zotero/storage/UI3APGHD/de Vienne et al. - 2011 - Euclidean Nature of Phylogenetic Distance Matrices.pdf:application/pdf;Snapshot:/Users/151569/.Zotero/storage/YVYQRCR4/1676258.html:text/html},
}

@inproceedings{sarkar2012lowa,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Low {Distortion} {Delaunay} {Embedding} of {Trees} in {Hyperbolic} {Plane}},
	isbn = {978-3-642-25878-7},
	doi = {10.1007/978-3-642-25878-7_34},
	abstract = {This paper considers the problem of embedding trees into the hyperbolic plane. We show that any tree can be realized as the Delaunay graph of its embedded vertices. Particularly, a weighted tree can be embedded such that the weight on each edge is realized as the hyperbolic distance between its embedded vertices. Thus the embedding preserves the metric information of the tree along with its topology. The distance distortion between non adjacent vertices can be made arbitrarily small – less than a (1 + ε) factor for any given ε. Existing results on low distortion of embedding discrete metrics into trees carry over to hyperbolic metric through this result. The Delaunay character implies useful properties such as guaranteed greedy routing and realization as minimum spanning trees.},
	language = {en},
	booktitle = {Graph {Drawing}},
	publisher = {Springer},
	author = {Sarkar, Rik},
	editor = {van Kreveld, Marc and Speckmann, Bettina},
	year = {2012},
	keywords = {Hyperbolic Plane, Minimum Span Tree, Voronoi Cell, Voronoi Diagram, Weighted Tree},
	pages = {355--366},
	file = {Springer Full Text PDF:/Users/151569/.Zotero/storage/87D6RGQP/Sarkar - 2012 - Low Distortion Delaunay Embedding of Trees in Hype.pdf:application/pdf},
}


